{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook deals with compiling all available estimates and measurements of vertical nitrate fluxes (in the Arctic Ocean).\n",
    "\n",
    "All figures exported from this notebook are prefixed by `FIGURE_NO3-COMP_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run imports.py\n",
    "\n",
    "dims = dict(\n",
    "    fndim = hv.Dimension('FN', label='Nitrate flux', unit='mmol m-2 d-1', range=(.005, 10)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Compiling the nitrate flux database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information was gathered into [a spreadsheet](../data/fn-compilation.xlsx) mainly from each reference, with auxiliary information sometimes coming from related publications. Other information needed some additional calculations based on published data. Note that for the nitrate fluxes newly calculated for this study, auxiliary calculations have already been done in [B0_new_estimates.ipynb](B0_new_estimates.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Surface nitrate concentration in Nishino et al., 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '../data/fn-compilation-database/nishino2018biogeochemical/bottle/MR150301_ex_bot.csv',\n",
    "    skiprows=[0, 2],\n",
    "    na_values = -999,\n",
    "    parse_dates = ['DATE']\n",
    ")\n",
    "\n",
    "df[['CTDDPT','NITRAT','NITRAT2','NITRAT_AVE']].loc[\n",
    "    (df.CTDDPT<=25) & \n",
    "    (dt.datetime(2015,9,23,0,0,0)<= df.DATE) &\n",
    "    (dt.datetime(2015,9,23,23,59,59)>= df.DATE)\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the average surface conc. as shown in Fig. 2b of their paper, is around 0.004 µM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinates in randelhoff2016vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CarbonBridge ISUS data as TSV:\n",
    "https://data.npolar.no/dataset/5134115e-6418-42f8-802d-07d86f780ebd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = loadmat('/Users/doppler/database/nitrate-fluxes/results_all.mat',\n",
    "           squeeze_me=True)\n",
    "df = gpd.GeoDataFrame(\n",
    "    dict(\n",
    "        ice=m['isice'],\n",
    "        fn=m['FN'],\n",
    "        lon=m['lon'],\n",
    "        lat=m['lat'],\n",
    "        time=m['time']\n",
    "    )\n",
    ")\n",
    "df['geometry'] = [Point(x,y) for x,y in zip(df.lon,df.lat)]\n",
    "df.groupby('ice').geometry.apply(lambda x: x.unary_union.convex_hull.centroid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## randelhoff2016regional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we only need to find representative positions to enter into the nitrate flux compilation CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canada, Amundsen, Makarov Basins"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Makarov Basin XCP locations in this file: ~/data/fn-compilation-database/randelhoff2016regional/deep_FN/john_canadian_basin/MMP_XCP_locations.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latitudes and longitudes already extracted from the file, are as follows:\n",
    "\n",
    "lat = [84,85,86,86,87,88,89,89,90,85,86,86,86,87,87,88,72.6666666666667,73,73,74.3333333333333,74.6666666666667,74,74,75]\n",
    "lon = [-135,90,-135,90,-135,90,-135,90,0,90,-136,-173,90,-137,-180,-180,-145,-140,-150,-143,-146,-140,-150,-150]\n",
    "\n",
    "# Amundsen Basin\n",
    "coords_AM = MultiPoint([Point(x,y) for x,y in zip(lon,lat) if x>0 and y>87] # NPEO ISUS\n",
    "                       + [Point(x,y) for x,y in zip([-7, -10, 0], [89, 87.5, 88.5])] # NPEO MSS casts\n",
    "                      ).convex_hull\n",
    "\n",
    "# Makarov Basin\n",
    "coords_MK = MultiPoint([Point(x,y) for x,y in zip(lon,lat) if x<0 and y>80] # NPEO ISUS\n",
    "                       + [Point(x,y) for x,y in zip( # XCP Makarov\n",
    "                           [-134.715666666667,-134.147500000000,-136.040000000000,-84.5061666666667],\n",
    "                           [84.4781666666667,85.7421666666667,88.5833333333333,89.0641666666667])]\n",
    "                      ).convex_hull\n",
    "\n",
    "# Canadian Basin\n",
    "coords_CB = MultiPoint([Point(x,y) for x,y in zip(lon,lat) if y<80] # NPEO ISUS\n",
    "                       + [Point(x,y) for x,y in zip([-150, -150, -140, -140],[72.5, 78, 77, 72.5])] # Beaufort Gyre exploration project moorings\n",
    "                      ).convex_hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_AM.centroid.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_MK.centroid.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_CB.centroid.wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nansen Basin/Yermak Plateau\n",
    "\n",
    "FN calculated using `CALC_FN_deep.m`.\n",
    "\n",
    "    nice = load('~/_WORK/_DATA/NICE/ISUS/NICE2015_ISUS_calibrated.mat')\n",
    "    isus = nice.isus([2:10 16]) \n",
    "\n",
    "data link: https://data.npolar.no/dataset/96eb41f9-c620-5fe4-a7a3-96b0e55fd3d5 as .nc file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('../data/fn-compilation-database/N-ICE2015-ISUS.nc')\n",
    "# stations in that file that were used to calculate the nitrate fluxes:\n",
    "stations = list(range(1,10))+[15,]\n",
    "\n",
    "ds.isel(LATITUDE=stations, LONGITUDE=stations)[['LONGITUDE', 'LATITUDE']].to_dataframe().reset_index().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert csv file into markdown table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/fn-compilation.csv')\n",
    "\n",
    "df['Reference'] = (\n",
    "    df.Reference.str.startswith('this study').apply(lambda b: '@' if not b else '')\n",
    "    + df.Reference\n",
    ")\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    #.assign(sorter=df.Reference.str.extract(r'(\\d{4})', expand=False)+df.Reference)\n",
    "    #.sort_values('sorter')\n",
    "    #.drop(columns='sorter')\n",
    "    .sort_values(['Area', 'Season', 'FN'])\n",
    "    .replace('single', 'Small')\n",
    "    .replace('Perennial', 'Winter')\n",
    "    .replace('aggregate', 'Large')\n",
    "    .replace('Microstructure', 'Microstruct.')\n",
    "    .replace('Finestructure', 'Finestruct.')\n",
    "    .replace(np.nan, 'N/A')\n",
    "    \n",
    ")\n",
    "\n",
    "df_export = (\n",
    "    df[['Area', 'Season', 'FN', 'Reference', 'samplesize', 'Turbulence_measurement', 'Nitrate_measurement']]\n",
    "    .rename(columns=dict(\n",
    "        samplesize='Sample size', \n",
    "        Nitrate_measurement='NO₃⁻ meas.',\n",
    "        Turbulence_measurement='Turbulence meas.',\n",
    "        Area='Region',\n",
    "        FN='NO₃⁻ flux\\*',\n",
    "    ))\n",
    ")\n",
    "\n",
    "\n",
    "s = pandas_df_to_markdown_table(df_export)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile nitrate fluxes from the world ocean outside the Arctic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One additional calculation based on Planas et al., 1999 :\n",
    "\n",
    "Table 1: Krho in m2 d-1, dNO3dz in mmol m-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    dict(\n",
    "        Krho=[0.097, 0.015, 0.491, 0.417, 0.796, 1.13, 0.266, 1.45, 1.76, 5.84, 4.15, 14.43, 1.14, 2.59],\n",
    "        dNO3dz=[0.0005, 0.0025, 0.0168, 0.0365, 0.0017, 0.049, 0.109, 0.159, 0.225, 0.268, 0.202, 0.146, 0.038, 0.030]\n",
    "    )\n",
    ")\n",
    "\n",
    "df['FN'] = df.Krho * df.dNO3dz\n",
    "\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert .xlsx to markdown table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/fn-compilation-world.csv')\n",
    "\n",
    "df['Reference'] = '@' + df.Reference\n",
    "df['Year'] = df.Reference.str.extract('([0-9]{4})')\n",
    "df = df.sort_values(['Year', 'Reference', 'FN'])\n",
    "df = df[['Reference', 'FN', 'Region']].rename(columns=dict(\n",
    "    FN='NO₃⁻ flux\\*',\n",
    "))\n",
    "print(pandas_df_to_markdown_table(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Arctic-worldwide nitrate fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split non-Arctic into coastal/shelf vs. open ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register more style options with the bokeh backend\n",
    "\n",
    "so = ['hatch_pattern', 'hatch_scale', 'hatch_alpha', 'hatch_weight']\n",
    "hv.Store.add_style_opts(hv.Area, so, backend='bokeh')\n",
    "hv.Store.add_style_opts(hv.Distribution, so, backend='bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv('../data/fn-compilation.csv').assign(world_region='Arctic').rename(columns={'Area': 'Region'}),\n",
    "        pd.read_csv('../data/fn-compilation-world.csv').assign(world_region=lambda x: 'Non-Arctic: '+x.Environment)\n",
    "    ],\n",
    "    sort=False,\n",
    ")\n",
    "df = df.loc[df.FN>1e-10]\n",
    "df = df.assign(logFN=np.log10(df.FN))\n",
    "\n",
    "options = [\n",
    "    opts.Distribution(\n",
    "        tools=['hover'], padding=(0, (0, 0.05)),\n",
    "        frame_width=500, frame_height=250,\n",
    "        show_grid=True,\n",
    "        xticks=[(logx, 10**logx) for logx in range(-3, 3)], \n",
    "        fill_color=hv.Cycle(['#AA5F77', '#2DA3A2', '#D6AE4A']),\n",
    "        #fill_color='w',\n",
    "        hatch_scale=16,\n",
    "        hatch_alpha=.3,\n",
    "        hatch_pattern=hv.Cycle(['|', ' ', 'v']),\n",
    "        line_width=2.5, hatch_weight=3, \n",
    "    ),\n",
    "    opts.NdOverlay(legend_position='top'),\n",
    "]\n",
    "\n",
    "l = (\n",
    "    df.hvplot.kde('logFN', by='world_region').opts()\n",
    "    .redim(\n",
    "        logFN=hv.Dimension('logFN', label='Nitrate flux', unit='mmol m⁻² d⁻¹', range=(-4, 3)),\n",
    "        Density='Probability density',\n",
    "    )\n",
    "    .opts(*options)\n",
    ")\n",
    "\n",
    "fname = '../nb_fig/FIGURE_FN-COMP_comparison_world'\n",
    "hv.save(l, fname+'.html')\n",
    "hv.output(l)\n",
    "l = l.opts(toolbar=None)\n",
    "hv.save(l, fname+'.png')\n",
    "save_bokeh_svg(l.opts(opts.Distribution(hatch_pattern=None), clone=True), fname+'.svg')\n",
    "# save_bokeh_svg(l, fname+'.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
