{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run imports.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Young Sound "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Young Sound bathymetry data is courtesy T. Vang & J. Bendtsen. We were not able to make this file available here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.load_dataset('../data/youngsound2015/YS2015_FN.nc')\n",
    "stations = gv.Points((ds.lon, ds.lat)).relabel('Co-located MSS/SUNA station')\n",
    "\n",
    "fname_bathymetry = '../data/youngsound2015/ys_bathy_v3.0_raw.nc'\n",
    "if os.path.exists(fname_bathymetry):\n",
    "    ds = xr.load_dataset(fname_bathymetry)\n",
    "    ds = ds.isel(Longitude=slice(None, None, 5), Latitude=slice(None, None, 5))\n",
    "    bathymetry = gv.QuadMesh(ds.Bathymetry, ['Longitude', 'Latitude'], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # Create coastlines by buffering union of data points with zero depth\n",
    "\n",
    "    platecarre_eps = from_epsg(4326)\n",
    "    nps_eps = from_epsg(3413)\n",
    "\n",
    "    df = ds.to_dataframe().reset_index()\n",
    "    df = df.loc[df.Landmask==1]\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=[Point(x, y) for x, y in zip(df.Longitude, df.Latitude)],\n",
    "        crs=platecarre_eps\n",
    "    ).to_crs(nps_eps)\n",
    "\n",
    "    coast_shp = gdf.unary_union.buffer(400).boundary[1]\n",
    "    coast_gs = gpd.GeoSeries([coast_shp], crs=nps_eps).to_crs(platecarre_eps)[0]\n",
    "    coast = gv.Shape(coast_gs.simplify(0.005))\n",
    "else:\n",
    "    coast = gv.Points([0, 0]).relabel('Coast data not available')\n",
    "    bathymetry = gv.Points([0, 0]).relabel('Bathymetry data not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = ccrs.LambertConformal(central_longitude=-21.)\n",
    "\n",
    "data_unavailable_kwarg = dict(backend='matplotlib', color='w', apply_extents=False, apply_ranges=False)\n",
    "options = [\n",
    "    opts.Feature(backend='matplotlib', projection=proj),\n",
    "    opts.Points(\n",
    "        backend='matplotlib', projection=proj, color='orange', s=50, ec='k', padding=.1, \n",
    "        show_legend=True, #legend_position='left'\n",
    "    ),\n",
    "    opts.Points('Coast data not available', **data_unavailable_kwarg),\n",
    "    opts.Points('Bathymetry data not available', **data_unavailable_kwarg),\n",
    "    opts.Shape(backend='matplotlib', linewidth=2),\n",
    "    opts.QuadMesh(backend='matplotlib', cmap=cmocean.cm.tempo_r, colorbar=True)\n",
    "]\n",
    "\n",
    "l = bathymetry.clone() * coast.clone() * stations\n",
    "\n",
    "def adjust(fig):\n",
    "    ax = fig.axes[0]\n",
    "    fig.set_size_inches(10, 6)\n",
    "\n",
    "    from utils.mpl import set_cartopy_grid\n",
    "    set_cartopy_grid(ax, lons=np.arange(-22.4, -19.4, .4), lats=np.arange(74.0, 75, 0.1))\n",
    "    \n",
    "    transform = ccrs.PlateCarree()._as_mpl_transform(ax)\n",
    "    arrowprops = dict(\n",
    "        facecolor='gray', arrowstyle='simple',\n",
    "        connectionstyle='arc3,rad=-0.2',\n",
    "        alpha=0.5\n",
    "    )\n",
    "    kwargs = dict(\n",
    "        xycoords=transform, fontsize=15,\n",
    "        arrowprops=arrowprops, ha='center', va='center'\n",
    "    )\n",
    "    ax.annotate(\n",
    "        'Outer sill to\\nGreenland Sea', xy=(-20.13, 74.27), xytext=(-20.4, 74.53), \n",
    "        **kwargs\n",
    "    )\n",
    "    ax.annotate(\n",
    "        'Inner sill', xy=(-21.8, 74.44), xytext=(-21.9, 74.3), \n",
    "        **kwargs\n",
    "    )\n",
    " \n",
    "fname = '../nb_fig/FIGURE_FN-NEW_YOUNGSOUND_map'\n",
    "fig = mplrender(l.opts(*options), fname=fname, hooks=[adjust])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unavailable_kwarg = dict(color='w', apply_extents=False, apply_ranges=False)\n",
    "options = [\n",
    "    # opts.Feature(projection=proj),\n",
    "    opts.Points(\n",
    "        frame_width=500,\n",
    "        # projection=proj, \n",
    "        color='orange', size=5, line_color='k', padding=.1, \n",
    "        show_legend=True, #legend_position='left'\n",
    "    ),\n",
    "    opts.Points('Coast data not available', **data_unavailable_kwarg),\n",
    "    opts.Points('Bathymetry data not available', **data_unavailable_kwarg),\n",
    "    opts.Shape(line_width=2),\n",
    "    opts.QuadMesh(cmap=cmocean.cm.tempo_r, colorbar=True, tools=['hover'])\n",
    "]\n",
    "\n",
    "l = l.opts(*options).redim(\n",
    "    Latitude=hv.Dimension('Latitude', unit='°N'),\n",
    "    Longitude=hv.Dimension('Longitude', unit='°E'),\n",
    ")\n",
    "\n",
    "l = (\n",
    "    l \n",
    "    * gv.Text(-20.1, 74.3, 'Outer sill') \n",
    "    * gv.Text(-21.75, 74.46, 'Inner sill')\n",
    ")\n",
    "hv.save(l, fname, fmt='html')\n",
    "panelA = l.clone().opts(title='A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydrographic transect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.load_dataset('../data/youngsound2015/YS2015_CTD.nc')\n",
    "\n",
    "def add_transect_distances(ctd):\n",
    "    \"\"\"\n",
    "    For dataframe ctd with columns 'lon', 'lat', 'station', \n",
    "    define cumulative distances along a transect from west to east.\n",
    "    \"\"\"\n",
    "    ctd = ctd.dropna(subset=['lat'])\n",
    "    df = ctd.copy()\n",
    "    ctd=gpd.GeoDataFrame(ctd.groupby('station').mean())\n",
    "    ctd['geometry'] = [Point(x,y) for x,y in zip(ctd.lon, ctd.lat)]\n",
    "    ctd.crs=from_epsg(4326)\n",
    "    ctd=ctd.to_crs(from_epsg(3413))\n",
    "\n",
    "    s = gpd.GeoSeries(ctd.sort_values(by='lon', ascending=True).geometry)\n",
    "\n",
    "    dist = ( np.sqrt(s.centroid.x.diff()**2 \n",
    "            + s.centroid.y.diff()**2)\n",
    "            .fillna(value=0).cumsum().rename('dist')/1e3) # in km\n",
    "\n",
    "    ctd = df.merge(dist, on='station', how='outer')\n",
    "    ctd = ctd.sort_values(by='dist',ascending=True)\n",
    "    return ctd\n",
    "\n",
    "df = ds[['lon', 'lat', 'station']].to_dataframe()\n",
    "# remove a station not part of the transect\n",
    "df = df.drop(df.loc[df.station=='Lerbugten'].index)\n",
    "# average over a bunch of stations that are close by and the difference between which does not matter for a transect over the entire fjord\n",
    "df.loc[df.station.str.startswith('SILL'), 'station'] = 'SILL'\n",
    "station2dist = add_transect_distances(df).groupby('station').dist.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CTD \n",
    "\n",
    "ds = xr.load_dataset('../data/youngsound2015/YS2015_CTD.nc')\n",
    "ds['dist'] = ('cast', station2dist.reindex(ds.station).values)\n",
    "ds = ds.to_dataframe().groupby(['P', 'dist']).mean().to_xarray()\n",
    "sal_label = 'B: Salinity [g kg-1]'\n",
    "# S = ds.S.hvplot.quadmesh().relabel(sal_label)\n",
    "S = ds.S.hvplot.contourf(levels=50).relabel(sal_label)\n",
    "\n",
    "# SUNA\n",
    "\n",
    "ds = xr.load_dataset('../data/youngsound2015/YS2015_SUNA.nc')\n",
    "ds['dist'] = ('cast', station2dist.reindex(ds.station).values)\n",
    "ds = ds.to_dataframe().groupby(['P', 'dist']).mean().to_xarray()\n",
    "ntr_label = 'C: Nitrate conc [µM]'\n",
    "ntr = ds.nitrate.hvplot.contourf(levels=20).relabel(ntr_label)\n",
    "\n",
    "# MSS\n",
    "\n",
    "ds = xr.load_dataset('../data/youngsound2015/YS2015_MSS.nc')\n",
    "ds['dist'] = ('set', station2dist.reindex(ds.station).values)\n",
    "df = ds.to_dataframe().reset_index()\n",
    "df.P = pd.cut(df.P, bins=np.arange(5, 100, 2), labels=np.arange(6, 100, 2))\n",
    "\n",
    "ds = df.groupby(['P', 'dist']).median().to_xarray()\n",
    "eps_label = 'D: Dissipation of TKE [log(W kg-1)]'\n",
    "eps = np.log10(ds.eps).hvplot.contourf().relabel(eps_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = dict(\n",
    "    dist=hv.Dimension('dist', label='Distance', unit='km', range=(0, 90)),\n",
    "    P=hv.Dimension('P', label='Pressure', unit='dbar', range=(0, 100)),\n",
    ")\n",
    "\n",
    "options = [\n",
    "    opts.Polygons(invert_yaxis=True), \n",
    "    opts.Polygons(sal_label, frame_height=150, cmap=cmocean.cm.dense, xaxis='bare', color_levels=50),\n",
    "    opts.Polygons(ntr_label, frame_height=150, xaxis='bare', clim=(0, 5), line_color='k'),\n",
    "    opts.Polygons(eps_label, frame_height=150, cmap=cmocean.cm.rain, color_levels=50),\n",
    "]\n",
    "\n",
    "l = (S + ntr + eps).cols(1).redim(**dims).opts(*options)\n",
    "\n",
    "panelB = l.clone()\n",
    "\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../nb_fig/FIGURE_FN-NEW_YOUNGSOUND_transect'\n",
    "hv.save(l, fname, fmt='html')\n",
    "hv.save(l.opts(toolbar=None), fname, fmt='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New/regenerated production incubations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_newP():\n",
    "    df = pd.read_csv('../data/youngsound2015/YS2015_N15_inc.csv')\n",
    "    df = df.rename(columns={\n",
    "        'newProd_uM_N_d-1': 'newP', 'regProd_uM_N_d-1': 'regP', \n",
    "        'depth_m': 'depth', 'NOx_init_uM': 'NOx',\n",
    "    })\n",
    "    df['fratio'] = df.newP / (df.newP + df.regP)\n",
    "    \n",
    "    # It is difficult to estimate integrated new production \n",
    "    # from measurements at only two depths. Here we give a very rough, and conservative, estimate,\n",
    "    # by assuming the 5 m value holds in the [0-5 m] interval and the 20 m value holds over [5, 20].\n",
    "    newPint = (\n",
    "        df.set_index(['depth', 'station']).newP.to_xarray()\n",
    "        * xr.DataArray(data=[5, 15], coords=dict(depth=[5, 20]), dims=['depth'])\n",
    "    ).sum(dim='depth').rename('newPint').to_dataframe()\n",
    "    return df.merge(newPint, on='station')\n",
    "\n",
    "df = load_newP()\n",
    "df['dist'] = station2dist.reindex(df.station).values\n",
    "\n",
    "# jitter distance by a small amount to accomodate both incubations at single station\n",
    "dx = 1\n",
    "df['dist_jitter'] = df.dist + df.depth.apply(lambda s: {5: -dx, 20: dx}[s])\n",
    "\n",
    "dims = dict(\n",
    "    newP=hv.Dimension('newP', label='New Production', unit='µM d⁻¹', range=(.001, 0.2)),\n",
    ")\n",
    "\n",
    "options = [\n",
    "    opts.Spikes(\n",
    "        padding=.1,\n",
    "        line_width=10,\n",
    "        logy=True,\n",
    "        position=1e-3,\n",
    "        frame_width=500, \n",
    "        color=hv.Cycle(['blue', 'orange']), show_legend=True\n",
    "    ),\n",
    "    opts.NdOverlay(legend_position='top_left')\n",
    "]\n",
    "\n",
    "l = hv.Dataset(df, ['dist_jitter', 'depth'], 'newP').to(hv.Spikes).overlay()\n",
    "l = l.redim(**dims)\n",
    "l.opts(*options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = hv.Spikes(np.log10(df.newPint.to_frame(name='newPint'))).redim(value='log_newPint').relabel('New production')\n",
    "newPint_hv = l\n",
    "newPint_hv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = xr.load_dataset('../data/youngsound2015/YS2015_FN.nc').to_dataframe().assign(station_type='')\n",
    "\n",
    "sill = ['GH01', 'YS3.02', 'Tyro07']\n",
    "\n",
    "on_sill = df.station.str.contains('SILL') | df.station.isin(sill)\n",
    "df.loc[on_sill, 'station_type'] = 'Sills'\n",
    "df.loc[~on_sill, 'station_type'] = 'Interior'\n",
    "\n",
    "display(HTML(df[['FN']].describe().to_html()))\n",
    "display(HTML(df.groupby('station_type').FN.describe().to_html()))\n",
    "display(HTML(df.groupby('station_type').mean().to_html()))\n",
    "\n",
    "options = [\n",
    "    opts.Distribution(\n",
    "        padding=(0, (0, 0.05)),\n",
    "        fill_color=hv.Cycle(['blue', 'orange']),\n",
    "        # fill_color=hv.Cycle(['#1b9e77','#d95f02','#7570b3']),\n",
    "        xticks=[(logx, 10**logx) for logx in range(-3, 3, 1)]\n",
    "    ),\n",
    "    opts.Spikes(spike_length=0.18, line_width=7, tools=['hover']),\n",
    "    opts.NdOverlay(legend_position='top_right'),\n",
    "]\n",
    "dims = dict(\n",
    "    logFN=hv.Dimension('logFN', label='Nitrate flux', unit='mmol m⁻² d⁻¹', range=(-3.5, 2.5)),\n",
    "    Density='Probability density',\n",
    ")\n",
    "\n",
    "l = df.assign(logFN=np.log10(df.FN)).hvplot.kde('logFN', by='station_type') * newPint_hv\n",
    "l = l.opts(*options).redim(**dims)\n",
    "\n",
    "l = l * hv.Text(-1.45, 0.55, 'Median:\\n0.04') * hv.Text(-0.2, 0.3, 'Median:\\n0.33')\n",
    "\n",
    "panelC = l.clone().opts(title='E')\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../nb_fig/FIGURE_FN-NEW_YOUNGSOUND_fn'\n",
    "hv.save(l, fname, fmt='html')\n",
    "hv.save(l.opts(toolbar=None), fname, fmt='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../nb_fig/FIGURE_FN-NEW_YOUNGSOUND'\n",
    "l = (panelA + panelB + panelC).cols(1)\n",
    "hv.save(l, fname, fmt='html')\n",
    "l = l.opts(toolbar=None)\n",
    "hv.save(l, fname, fmt='png')\n",
    "\n",
    "os.system('rm ../nb_fig/FIGURE_FN-NEW_YOUNGSOUND_*.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "subprocess.run([\n",
    "    'convert',\n",
    "    '../nb_fig/FIGURE_FN-NEW_YOUNGSOUND_map.png',\n",
    "    '../nb_fig/FIGURE_FN-NEW_YOUNGSOUND_transect.png',\n",
    "    '../nb_fig/FIGURE_FN-NEW_YOUNGSOUND_fn.png',\n",
    "    '-append',\n",
    "    '../nb_fig/FIGURE_FN-NEW_YOUNGSOUND.png'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laptev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = dict(\n",
    "    Nitrate=hv.Dimension('Nitrate', range=(0, None), unit='µM'),\n",
    "    eps=hv.Dimension('eps', label='Dissipation', unit='W kg⁻¹'),\n",
    "    Depth=hv.Dimension('Depth', unit='m'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Winter/summer NO3 profiles from 2008/2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Only executed when there is access to the raw data files.\n",
    "    renamedict = {\n",
    "        'Lon [ｰE]':'lon',\n",
    "        'Lat [ｰN]': 'lat',\n",
    "        'Nitrate [umol/l]': 'nitrate',\n",
    "        'bottle Salinity [psu]': 'sal',\n",
    "        'Cruise': 'cruise',\n",
    "        'mon/day/yr': 'date',\n",
    "        'Temperature [ｰC]': 'temp',\n",
    "        'Depth [m]': 'depth',\n",
    "        'Station': 'station'\n",
    "    }\n",
    "\n",
    "    sel = ['date','lat','lon','nitrate','depth','temp','sal','station','cruise']\n",
    "\n",
    "    kwargs = dict(parse_dates=['mon/day/yr'], dtype={'Station': str}, date_parser=lambda x: pd.datetime.strptime(x, '%m/%d/%Y'))\n",
    "    dfs = pd.read_excel('../data/laptev/nitrate_2011/LaptevData.xlsx', **kwargs)\n",
    "    dfw = pd.read_excel('../data/laptev/nitrate_2008/LaptevData2.xlsx', **kwargs)\n",
    "    df = pd.concat([dfw, dfs], sort=False)\n",
    "    df = df.rename(columns=renamedict).dropna(how='all', subset=['nitrate'])[sel]\n",
    "\n",
    "    df = df.assign(month=lambda d: d.date.dt.month)\n",
    "    df.depth = pd.to_numeric(pd.cut(df.depth, bins=np.arange(0, 80, 5), labels=np.arange(2.5, 75, 5)))\n",
    "\n",
    "\n",
    "    # extract data in publishable format\n",
    "    metadata_dims = ['lon', 'lat', 'date', 'month', 'station']\n",
    "    #\n",
    "    df_winter = df.loc[df.month<=6]\n",
    "    df_winter_mean = df_winter.groupby('depth').mean().dropna(how='all')\n",
    "    df_winter_meta = df_winter[metadata_dims].groupby('station', as_index=False).first()\n",
    "    #\n",
    "    closest_summer_stations = np.array([4, 5, 20, 25]).astype(str)\n",
    "    df_summer = df.loc[df.station.isin(closest_summer_stations)]\n",
    "    df_summer_mean = df_summer.groupby('depth').mean().dropna(how='all')\n",
    "    df_summer_meta = df_summer[metadata_dims].groupby('station', as_index=False).first()\n",
    "\n",
    "    # save\n",
    "    df_winter_mean.to_csv('../data/laptev/nitrate_2008/mean_profile.csv')\n",
    "    df_summer_mean.to_csv('../data/laptev/nitrate_2011/mean_profile.csv')\n",
    "    df_winter_meta.to_csv('../data/laptev/nitrate_2008/metadata.csv')\n",
    "    df_summer_meta.to_csv('../data/laptev/nitrate_2011/metadata.csv')\n",
    "\n",
    "except:\n",
    "    # Otherwise, use the previously exported files\n",
    "    df_winter_mean, df_summer_mean, df_winter_meta, df_summer_meta = (\n",
    "      pd.read_csv('../data/laptev/nitrate_2008/mean_profile.csv'),\n",
    "      pd.read_csv('../data/laptev/nitrate_2011/mean_profile.csv'),\n",
    "      pd.read_csv('../data/laptev/nitrate_2008/metadata.csv'),\n",
    "      pd.read_csv('../data/laptev/nitrate_2011/metadata.csv'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define holoviews data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_winter = 'Winter 2008 mean'\n",
    "\n",
    "ntr_winter2008 = hv.Curve(df_winter_mean, 'depth', 'nitrate', label=label_winter) \n",
    "sal_winter2008 = hv.Curve(df_winter_mean, 'depth', 'sal', label=label_winter)\n",
    "loc_winter2008 = gv.Points(df_winter_meta, ['lon', 'lat'], ['date', 'month', 'station'], \n",
    "                        crs=ccrs.PlateCarree(), label='Winter 2008')\n",
    "\n",
    "\n",
    "label_summer = 'Summer 2011 mean'\n",
    "\n",
    "ntr_summer2011 = hv.Curve(df_summer_mean, 'depth', 'nitrate', label=label_summer)\n",
    "sal_summer2011 = hv.Curve(df_summer_mean, 'depth', 'sal', label=label_summer)\n",
    "loc_summer2011 = gv.Points(df_summer_meta, ['lon', 'lat'], ['date', 'month', 'station'], \n",
    "                        crs=ccrs.PlateCarree(), label='Summer 2011')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nitrate fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nitrate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining CTD cast number 59 with MSS profile number TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nitrate2018(fname):\n",
    "    column_names = [\n",
    "        'CTD time',\n",
    "        'Pressure',\n",
    "        'Depth',\n",
    "        'Primary temperature',\n",
    "        'Secondary temperature',\n",
    "        'Primary conductivity',\n",
    "        'Secondary conductivity',\n",
    "        'Primary salinity',\n",
    "        'Secondary salinity',\n",
    "        'Dissolved oxygen [mL L-1]',\n",
    "        'Oxygen voltage',\n",
    "        'CDOM',\n",
    "        'CHL',\n",
    "        'Turbidity',\n",
    "        'Beam-c',\n",
    "        'PAR',\n",
    "        'Transmission',\n",
    "        'Nitrate_uncorrected',\n",
    "        'Nitrate',\n",
    "    ]\n",
    "\n",
    "    df = pd.read_csv('../data/laptev/nabos_2018/suna_data/'+fname, sep='\\t', names=column_names)\n",
    "    \n",
    "    df['sigma0'] = gsw.sigma0(df['Primary salinity'], df['Primary temperature'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux estimate no. 1: NABOS Cast 59+2018 MSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = '2018 cast 59'\n",
    "df = load_nitrate2018('AT18_59.txt')\n",
    "ntr_2018_59 = df.hvplot('Depth', 'Nitrate').relabel(label)\n",
    "sal_2018_59 = df.hvplot('Depth', 'Primary salinity').relabel(label)\n",
    "loc_2018_59 = gv.Points((125.857, 77.011), crs=ccrs.PlateCarree(), label='2018 MSS+SUNA station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mss2018():\n",
    "    a = loadmat('../data/laptev/nabos_2018/MSS2018.mat', squeeze_me=True)\n",
    "\n",
    "    a.pop('__header__')\n",
    "    a.pop('__version__')\n",
    "    a.pop('__globals__')\n",
    "\n",
    "    ds = xr.Dataset(coords=dict(P=a['P_2018'][0, :], cast=np.arange(a['P_2018'].shape[0])))\n",
    "    a.pop('P_2018')\n",
    "\n",
    "    # rename variables from *_2018 to just *\n",
    "    for var, vals in a.items():\n",
    "        ds[var[:-5]] = (['cast', 'P'], vals)\n",
    "\n",
    "    ds['eps'] = 10**ds.eps\n",
    "\n",
    "    ds['sigma'] = (['cast', 'P'], gsw.sigma0(ds.S, ds.T))\n",
    "\n",
    "    def calc_N2(P, sigma):\n",
    "        dsigma_dz = np.polyfit(P, sigma.sort_values(), 1)[0]\n",
    "        return gsw.grav(75, np.nanmean(P)) / (1e3+np.nanmean(sigma)) * dsigma_dz\n",
    "\n",
    "    df = ds.to_dataframe().reset_index()\n",
    "\n",
    "    df['P_bin'] = pd.cut(df.P, bins=np.arange(0, 300, 5))\n",
    "\n",
    "    df = df.merge(\n",
    "        df.groupby(['P_bin', 'cast'])\n",
    "        .apply(lambda g: calc_N2(g.P, g.sigma))\n",
    "        .rename('N2'),\n",
    "        right_index=True,\n",
    "        left_on=['P_bin', 'cast'],\n",
    "        how='outer'\n",
    "    ).dropna(subset=['P', 'N2', 'eps'])\n",
    "\n",
    "    # Osborn 1980 parameterization\n",
    "    df['Krho'] = 0.2 * df.eps / df.N2\n",
    "\n",
    "    df = df.groupby('P', as_index=False).median()\n",
    "    return df\n",
    "\n",
    "eps_label = '2018'\n",
    "eps_2018_59 = load_mss2018().hvplot('P', 'eps').relabel(group='eps', label='2018').opts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viz + calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_viz_options = [\n",
    "    opts.Curve(\n",
    "        title='',\n",
    "        invert_axes=True, invert_yaxis=True,\n",
    "        frame_width=200, height=400, xaxis='top',\n",
    "        line_color='blue',\n",
    "    ),\n",
    "    opts.Curve(\n",
    "        'eps', \n",
    "        logx=True, \n",
    "        #xticks=[(1e-9, '10⁻⁹'), (1e-7, '10⁻⁷'), (1e-5, '10⁻⁵')],\n",
    "        yaxis='bare'\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ntr_2018_59 + eps_2018_59\n",
    "l = l.opts().opts(*fn_viz_options)\n",
    "hv.output(l) # the nitracline is between 10 and 25 meters depth\n",
    "\n",
    "# clear options\n",
    "l = l.opts().opts(opts.Curve('eps'))\n",
    "df_ntr = ntr_2018_59.data\n",
    "df_mss = eps_2018_59.data\n",
    "\n",
    "df_nitracline = df_ntr.loc[df_ntr.Depth.between(10, 25)]\n",
    "print('Nitrate flux: [mmol/m2/d]')\n",
    "(\n",
    "    np.polyfit(df_nitracline.Depth, df_nitracline.Nitrate, 1)[0] \n",
    "    * df_mss.loc[df_mss.P.between(10, 25)].median().Krho * 86400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Flux estimate no. 2: NABOS Cast 62 + 2014 MSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mss2014():\n",
    "    df_list = []\n",
    "    for i in range(7, 12):\n",
    "        d = loadmat(f'../data/laptev/mss_2014/msp_____{i:04d}.mat', squeeze_me=True)['ppd']\n",
    "        extract_vars = ['press', 'epsilon', 'asal']#, 'krho', 'bvf2', 'Re_b']\n",
    "\n",
    "        df = pd.DataFrame(columns=extract_vars)\n",
    "        for var in extract_vars:\n",
    "            df[var] = d['data'][()][:, d['sensors'][()] == var].squeeze()\n",
    "        df.epsilon = 10**df.epsilon\n",
    "        df_list.append(df)\n",
    "\n",
    "    df = (\n",
    "        pd.concat(df_list)\n",
    "        .groupby('press', as_index=False).median()\n",
    "        .rename(columns={'asal': 'sal'})\n",
    "    )\n",
    "    df['depth'] = -gsw.z_from_p(df.press, 76.)\n",
    "    df = df.rename(columns=dict(press='P', epsilon='eps'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_mss2014()\n",
    "\n",
    "eps_2014 = df.hvplot('depth', 'eps').relabel('MSS 2014').opts()\n",
    "loc_mss2014 = gv.Points(\n",
    "    (125.98045, 76.30767), ['lon', 'lat'],\n",
    "    crs=ccrs.PlateCarree(), label='MSS station 2014'\n",
    ")\n",
    "\n",
    "sal_2014 = hv.Curve(df, 'depth', 'sal', label='MSS Station 2014')\n",
    "eps_2014 = hv.Curve(df, 'depth', 'eps', label='2014', group='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = '2018 cast 62'\n",
    "df = load_nitrate2018('AT18_62.txt')\n",
    "ntr_2018_62 = df.hvplot('Depth', 'Nitrate').relabel(label)\n",
    "sal_2018_62 = df.hvplot('Depth', 'Primary salinity').relabel(label)\n",
    "loc_2018_62 = gv.Points((125.122, 76.351), crs=ccrs.PlateCarree(), label='2018 SUNA cast 62')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viz + calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ntr_2018_62 + eps_2014\n",
    "l = l.opts().opts(*fn_viz_options)#.redim(**dims).opts(toolbar=None)\n",
    "hv.output(l) # from this Figure, we read off the nitracline between 15 and 20 meters depth.\n",
    "\n",
    "# clear options\n",
    "l = l.opts().opts(opts.Curve('eps'))\n",
    "df_ntr = ntr_2018_62.data\n",
    "df_eps = eps_2014.data\n",
    "\n",
    "df_ntr_nitracline = df_ntr.loc[df_ntr.Depth.between(15, 20)]\n",
    "df_eps_nitracline = df_eps.loc[df_eps.P.between(15, 20)]\n",
    "\n",
    "print('Nitrate flux: [mmol/m2/d]')\n",
    "dNTR_dz = np.polyfit(df_ntr_nitracline.Depth, df_ntr_nitracline.Nitrate, 1)[0] \n",
    "N2 = 9.81/(1e3 + df_ntr_nitracline.sigma0.mean()) * np.polyfit(df_ntr_nitracline.Depth, df_ntr_nitracline.sigma0, 1)[0] \n",
    "eps = df_eps_nitracline.median().eps\n",
    "\n",
    "# calculate nitrate flux using Osborn 1980 approximation (mixing efficiency 0.2)\n",
    "dNTR_dz * 0.2 * eps / N2 * 86400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average of both flux estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With one being 0.014 and the other 0.017 (see above), we can comfortably use 0.015 mmol m-2 d-1 as the upward nitrate flux through the seasonal halocline in summer in the Laptev sea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz: Vertical profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = dict(\n",
    "    depth=hv.Dimension('depth', label='Depth', unit='m', range=(0, 55)),\n",
    "    nitrate=hv.Dimension('nitrate', label='NO₃ conc.', unit='µM', range=(0, 7)),\n",
    "    sal=hv.Dimension('sal', label='Salinity', unit='g kg⁻¹'),\n",
    "    eps=hv.Dimension('eps', label='TKE Dissipation', unit='W kg⁻¹', range=(5e-10, 5e-4)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "\n",
    "options = [\n",
    "    opts.Curve(\n",
    "        title='{label}',\n",
    "        invert_axes=True, invert_yaxis=True, xaxis='top',\n",
    "        show_grid=True, show_legend=True,\n",
    "        tools=['hover'],\n",
    "        frame_width=200, frame_height=400,\n",
    "        padding=.05,\n",
    "        line_width=3,\n",
    "    ),\n",
    "    opts.Curve('eps', logx=True, xticks=[(1e-9, '10⁻⁹'), (1e-7, '10⁻⁷'), (1e-5, '10⁻⁵')]),\n",
    "    opts.Overlay(legend_position='bottom_left', title='{label}', show_title=False),\n",
    "    opts.NdLayout(title='{label}'),\n",
    "]\n",
    "\n",
    "# options = translate_options(options, bokeh2mpl)\n",
    "\n",
    "panels = [\n",
    "    hv.Overlay([sal_winter2008, sal_summer2011, sal_2018_62, sal_2018_59, ], label='A'),\n",
    "    hv.Overlay([ntr_winter2008, ntr_summer2011, ntr_2018_62, ntr_2018_59], label='B'),\n",
    "    hv.Overlay([eps_2014, eps_2018_59], label='C'),\n",
    "]\n",
    "\n",
    "\n",
    "# apply options to all the panels to avoid option matplotlib/bokeh conflicts before linking the styles\n",
    "_ = hv.Layout(panels).opts().opts(opts.Curve('eps', xticks=None))\n",
    "sl = StyleLink(\n",
    "    [\n",
    "        [ntr_winter2008, sal_winter2008], \n",
    "        [ntr_summer2011, sal_summer2011], \n",
    "        [ntr_2018_59, sal_2018_59, eps_2018_59], \n",
    "        [sal_2014, eps_2014, ntr_2018_62, sal_2018_62], \n",
    "    ],\n",
    "    {\n",
    "        'line_color': hv.Cycle(cmap_to_list(colorcet.cm.glasbey_bw_minc_20_maxl_70)),\n",
    "        'line_dash': hv.Cycle(['dashdot', 'dashed', 'dotted', 'solid'])\n",
    "    }\n",
    ")\n",
    "# l = hv.Layout(panels).redim(**dims).opts(*options)\n",
    "l = hv.NdLayout({k: panel for k, panel in enumerate(panels)}).redim(**dims).opts(*options)\n",
    "laptev_profiles = l.clone()\n",
    "hv.output(l)\n",
    "fname = '../nb_fig/FIGURE_FN-NEW_LAPTEV_profiles'\n",
    "hv.save(l, fname, fmt='html')\n",
    "hv.save(l.opts(toolbar=None), fname, fmt='png')\n",
    "save_bokeh_svg_multipanel(l, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertically integrated NO3 difference from summer to winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaN = (df_winter_mean.nitrate - df_summer_mean.nitrate).sum()*5 # delta_nitrate * delta_z (5 m for each bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If mixing extends over 4 months and if (!) we can neglect cycling processes in the water column/benthos, the flux would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaN / 4/30 # mmol m-2 d-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, given the shapes of the winter/summer profiles, it appears likely that benthic processes and/or advection have affected the nitrate concentrations. Hence this estimate may not be worth much. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz: Map of all stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lenn et al., 2011, \"Intermittent Intense Turbulent Mixing under Ice in the Laptev Sea Continental Shelf\": NLS station (drift) and CLS station (mooring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenn2011 = (\n",
    "    gv.Points((144+56.13/60, 79+14.81/60), ['lon', 'lat'],\n",
    "              label='Lenn et al. 2011, turbulence obs.')\n",
    "    * gv.Points((125+55.3/60, 76+44./60), ['lon', 'lat'],\n",
    "                label='Lenn et al. 2011, mooring')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "\n",
    "proj = ccrs.LambertConformal(central_longitude=110, central_latitude=75)\n",
    "\n",
    "print('PROJ4 string:')\n",
    "print(proj.proj4_init)\n",
    "\n",
    "def visaxes(plot, element):\n",
    "    plot.state.axis.visible = True\n",
    "    \n",
    "options = [\n",
    "    opts.Points(\n",
    "        color=hv.Cycle(cmap_to_list(colorcet.cm.glasbey_light)),\n",
    "        marker=hv.Cycle(['circle', 'triangle', 'diamond', 'square']),\n",
    "        jitter=True, tools=['hover'], \n",
    "        frame_height=500, aspect=1,\n",
    "        size=15, projection=proj,\n",
    "        hooks=[visaxes],\n",
    "        xlabel='x (m)', ylabel='y (m)'\n",
    "    ),\n",
    "    opts.Points('MSS station 2014', marker='square', size=20, padding=.1),\n",
    "    opts.Shape(\n",
    "        'Bathymetry',\n",
    "        show_legend=True, line_width=2,\n",
    "        #line_color=hv.Cycle(cmap_to_list(colorcet.cm.glasbey_dark)), \n",
    "        line_color='black',\n",
    "        line_dash=hv.Cycle(['solid', 'dashed', 'dotted']),\n",
    "    ),\n",
    "    opts.Shape(\n",
    "        'Land',\n",
    "        fill_color='wheat', line_color='black'\n",
    "    ),\n",
    "    opts.Overlay(show_legend=True, legend_position='right'),\n",
    "]\n",
    "\n",
    "\n",
    "# lb = gv.Labels(df, ['lon', 'lat'], 'station')\n",
    "\n",
    "# geography\n",
    "extents = (90, 60, 160, 90)\n",
    "bbox = box(*extents)\n",
    "land_feature = gv.feature.land.data.with_scale('10m')\n",
    "land = gv.Shape(unary_union([geom.intersection(bbox) for geom in land_feature.geometries()])).relabel(group='Land')\n",
    "\n",
    "bathymetry = hv.Overlay([gv.Shape(bathy.loc[depth].intersection(bbox), group='Bathymetry', label=f'{depth} m isobath') for depth in [50, 200, 1000]])\n",
    "\n",
    "l = (\n",
    "    bathymetry\n",
    "    * loc_winter2008\n",
    "    * loc_summer2011\n",
    "    * loc_2018_59\n",
    "    * loc_mss2014\n",
    "    * loc_2018_62\n",
    "    * lenn2011\n",
    "    * land\n",
    "    # * gv.feature.rivers.opts(line_width=3, color='blue', scale='110m')\n",
    ")\n",
    "    \n",
    "l = l.opts(*[options]).redim.range(lon=(100, 150), lat=(71, 80))\n",
    "\n",
    "laptev_map = l.clone()\n",
    "fname = '../nb_fig/FIGURE_FN-NEW_LAPTEV_map'\n",
    "hv.save(l, fname+'.html')\n",
    "hv.save(l.opts(toolbar=None, clone=True), fname+'.png')\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge profiles and map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = (laptev_profiles + laptev_map.opts(title='B')).cols(1)\n",
    "fname = '../nb_fig/FIGURE_FN-NEW_LAPTEV'\n",
    "hv.save(l, fname, fmt='html')\n",
    "hv.save(l.opts(toolbar=None, clone=True), fname, fmt='png')\n",
    "os.system(f'rm ../nb_fig/FIGURE_FN-NEW_LAPTEV_*.png')\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bio-Argo floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = {\n",
    "    'Depth': hv.Dimension('Depth', unit='m', range=(0, None)),\n",
    "    'CorNO3': hv.Dimension('CorNO3', label='NO₃', unit='µM', range=(0, None)),\n",
    "    'NO3int': hv.Dimension('NO3int', label='NO₃ deficit', unit='mmol m⁻²', range=(0, None)),\n",
    "    'Date': hv.Dimension('Date', range=(pd.Timestamp('2017-8-1'), pd.Timestamp('2018-8-1')))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../data/baffin/FLOATS_by_date_derived.nc'\n",
    "\n",
    "if os.path.exists(fname):\n",
    "\n",
    "    def load_floats(fname, bin_average=False):\n",
    "        ds = xr.open_dataset(fname)\n",
    "\n",
    "        if bin_average:\n",
    "            date_bins = pd.date_range(ds.Date[0].values, ds.Date[-1].values, freq='MS')\n",
    "            date_labels = date_bins[:-1]\n",
    "\n",
    "            depth_bins = np.arange(0., 200, 4)\n",
    "            depth_labels = depth_bins[:-1] + 2\n",
    "\n",
    "            df = ds.to_dataframe().reset_index()\n",
    "            df.Date = pd.cut(df.Date, bins=date_bins, labels=date_labels)\n",
    "            df.Depth = pd.to_numeric(pd.cut(df.Depth, bins=depth_bins, labels=depth_labels))\n",
    "\n",
    "            ds = df.groupby(['Date', 'Depth']).mean().to_xarray()\n",
    "\n",
    "        return ds\n",
    "\n",
    "    # monthly averages of NO3 and MLD\n",
    "    ds = load_floats(fname, bin_average=True)\n",
    "    ds = ds.sel(dict(Depth=ds.Depth[ds.Depth<=100.]))\n",
    "    ds['mld'] = ds.mld.reduce(get_unique, dim='Depth')\n",
    "\n",
    "    ds = ds[['Date', 'Depth', 'CorNO3', 'mld']]\n",
    "    \n",
    "    ds.to_netcdf('../data/baffin/baffin_monthly.nc')\n",
    "\n",
    "    # Surface layer NO3 deficit\n",
    "    zref=60\n",
    "    ds = load_floats(fname)\n",
    "    ds = ds.sel(Depth=slice(0, zref))\n",
    "\n",
    "    # mmol/m2\n",
    "    NO3int = (ds.CorNO3.isel(dict(Depth=-1)) - ds.CorNO3).sum(\n",
    "        dim='Depth',min_count=1).rename('NO3int')\n",
    "\n",
    "    #mmol/m2/d\n",
    "    dNO3= NO3int.diff(dim='Date').rename('dNO3')\n",
    "\n",
    "    df_dno3 = NO3int.mean(dim='Float').to_dataframe()\n",
    "    df_dno3.to_csv('../data/baffin/no3_deficit_daily.csv')\n",
    "    \n",
    "ds = xr.load_dataset('../data/baffin/baffin_monthly.nc')\n",
    "df_dno3 = pd.read_csv('../data/baffin/no3_deficit_daily.csv', index_col='Date', parse_dates=['Date'])\n",
    "df_dno3_avg = df_dno3.NO3int.rolling(15, center=True).mean().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dno3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntr = ds.hvplot.quadmesh('Date', 'Depth', 'CorNO3').opts()\n",
    "mld = ds.mld.hvplot(label='Mixed Layer Depth')\n",
    "\n",
    "def adjust(plot, element):\n",
    "    p = plot.state\n",
    "    c = p.select(dict(type=ColorBar))[0]\n",
    "    \n",
    "    c.title = element.vdims[0].pprint_label\n",
    "    c.location = (0, -10)\n",
    "    c.height = 220\n",
    "        \n",
    "# Panel 1 \n",
    "p1 = (ntr*mld).opts(\n",
    "    opts.QuadMesh(\n",
    "        width=500, height=310,\n",
    "        hooks=[adjust], tools=['hover'],\n",
    "        invert_yaxis=True, \n",
    "        cmap=cmocean.cm.turbid, colorbar=True,\n",
    "    ),\n",
    "    opts.Curve(\n",
    "        color='#12d9e3', line_width=3,\n",
    "        show_legend=True\n",
    "    ),\n",
    "    opts.Overlay(legend_position='bottom_left')\n",
    ")\n",
    "\n",
    "# Panel 2\n",
    "\n",
    "p2 = (\n",
    "    df_dno3.reset_index().hvplot.scatter('Date', 'NO3int', color='grey').opts(yticks=[0, 100, 200, 300])\n",
    "    * df_dno3_avg.hvplot(color='k', line_width=3)\n",
    ").opts(show_legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = theme\n",
    "\n",
    "l = p1.relabel('A') + p2.relabel('B')\n",
    "l = l.redim(**dims).opts(\n",
    "    opts.Overlay(width=600, xrotation=30, xlabel='',)\n",
    ").cols(1)\n",
    "\n",
    "fname = '../nb_fig/FIGURE_FN-NEW_BAFFIN'\n",
    "hv.save(l, fname+'.html')\n",
    "hv.save(l.opts(toolbar=None), fname+'.png')\n",
    "save_bokeh_svg_multipanel(l, fname, 'v')\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read off from Panel B that the nitrate deficit was decreased by 200 mmol m-2 over the course of four months. The upward nitrate flux at 60 m depth is hence approximately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "200/4/30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the the center coordinate of the BGC Argo float observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "coords = df[['Longitude','Latitude']].dropna()\n",
    "print(\n",
    "    MultiPoint(\n",
    "        [Point(x,y) for x,y in zip(coords.Longitude,coords.Latitude)]\n",
    "    ).convex_hull.centroid.wkt\n",
    ")\n",
    "```\n",
    "> POINT (-65.36189062114981 72.22652198050153)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Chukchi Sea: Calculation based on nishino2015nutrient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nishino_etal_2015():\n",
    "    return pd.read_csv('../data/fn-compilation-database/nishino2015nutrient/Data_from_Mirai2013.csv',na_values=-999, parse_dates=['yyyy-mm-ddThh:mm:ss.sss'])\n",
    "df = load_nishino_etal_2015()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['logFN'] = np.abs(np.log10(df['Flux_N1 [mmol/m~^2~#/s]']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [\n",
    "    opts.Curve(invert_yaxis=True, invert_axes=True),\n",
    "]\n",
    "no3 = hv.Curve(df, 'Depth [m]', ['Nitrate [~$m~#mol/kg]', 'Station','yyyy-mm-ddThh:mm:ss.sss'])\n",
    "fn = hv.Curve(df, 'Depth [m]', ['Flux_N1 [mmol/m~^2~#/s]', 'Station'])\n",
    "l = no3.groupby('Station').overlay() + fn.groupby('Station').overlay()\n",
    "l.options(*options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comprises three wind events, supposedly leading to enhanced mixing:\n",
    "\n",
    "1. 14-15 Sep\n",
    "1. 19-21 Sep\n",
    "1. 24-25 Sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll naively sum the provided depth-dependent nitrate fluxes, which were originally obtained by multiplying dissipation of TKE, buoyancy frequency, and nitrate gradient for each depth interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df['yyyy-mm-ddThh:mm:ss.sss']\n",
    "\n",
    "z_interval=[25,40]\n",
    "\n",
    "iz = (df['Depth [m]']>=z_interval[0]) & (df['Depth [m]']<=z_interval[1])\n",
    "ii1 = (\n",
    "    (time <= dt.datetime(2013,9,15,23,59,59)) & \n",
    "    (time >= dt.datetime(2013,9,14,0,0,0))\n",
    ")\n",
    "ii2 = (\n",
    "    (time <= dt.datetime(2013,9,21,23,59,59)) & \n",
    "    (time >= dt.datetime(2013,9,19,0,0,0))\n",
    ")\n",
    "ii3 = (\n",
    "    (time <= dt.datetime(2013,9,25,23,59,59)) & \n",
    "    (time >= dt.datetime(2013,9,24,0,0,0))\n",
    ")\n",
    "\n",
    "for the_vars in [\n",
    "    ['Flux_N1 [mmol/m~^2~#/s]','Flux_N2 [mmol/m~^2~#/s]'],\n",
    "    ['Krho1 [m~^2~#/s]', 'Krho2 [m~^2~#/s]']\n",
    "]:\n",
    "    if the_vars[0].startswith('Krho'):\n",
    "        print('Krho in m2/d:')\n",
    "    elif the_vars[0].startswith('Flux_N'):\n",
    "        print('Nitrate flux in mmmol/m2/d:')\n",
    "\n",
    "    print('Each wind event:')\n",
    "    for ii in [ii1,ii2,ii3]:\n",
    "        print(df.loc[ii & iz, the_vars].mean().mean()*86400)\n",
    "\n",
    "    print('All wind events:')\n",
    "    print(df.loc[(ii1 | ii2 | ii3) & iz,the_vars].mean().mean()*86400)\n",
    "\n",
    "    print('Entire time series:')\n",
    "    var_mean = df.loc[iz, the_vars].mean().mean()*86400\n",
    "    print(var_mean)\n",
    "    if the_vars[0].startswith('Krho'):\n",
    "        Krho = var_mean\n",
    "    elif the_vars[0].startswith('Flux_N'):\n",
    "        FN = var_mean\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, as a more reliable means of averaging the turbulent flux over the (non-turbulent) background field, we determine the nitrate gradient over the same depth interval and multiply that by the average eddy diffusivity: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['Depth [m]']).mean()\n",
    "df = df.loc[(df.index>=z_interval[0]) & (df.index <= z_interval[1]), 'Nitrate [~$m~#mol/kg]']\n",
    "print('dNO3/dz in uM/m:')\n",
    "no3_slope = np.polyfit(df.index,df.values, 1)[0]\n",
    "no3_slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above first estimate is consistent with this second, arguably more accurate, averaging method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Krho * no3_slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface NO3 concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_nishino_etal_2015()\n",
    "df.loc[df['Depth [m]']<=10, 'Nitrate [~$m~#mol/kg]'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaged station coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.groupby('Station').first()\n",
    "LineString(zip(d['Longitude [degrees_east]'],d['Latitude [degrees_north]'])).centroid.wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In degrees Longitude West:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "191.75-360"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
